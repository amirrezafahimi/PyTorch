{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import itertools\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.FashionMNIST(root=\".\", \n",
    "                                                  train=True, \n",
    "                                                  transform=transforms.ToTensor(), \n",
    "                                                  download=True)\n",
    "train_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.FashionMNIST(root=\".\", \n",
    "                                                 train=False, \n",
    "                                                 transform=transforms.ToTensor(), \n",
    "                                                 download=True)\n",
    "test_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(set(train_dataset.targets.numpy()))\n",
    "number_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, number_of_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=2), \n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2), \n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128 * 2 * 2, 512), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2), \n",
    "            nn.Linear(512, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2), \n",
    "            nn.Linear(200, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2), \n",
    "            nn.Linear(100, number_of_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "    out = self.conv_layers(X)\n",
    "    out = out.view(out.size(0), -1)\n",
    "    out = self.dense_layers(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(number_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = nn.Sequential(\n",
    "#     nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=2), \n",
    "#     nn.ReLU(), \n",
    "#     nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2), \n",
    "#     nn.ReLU(), \n",
    "#     nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2), \n",
    "#     nn.ReLU(), \n",
    "#     nn.Flatten()\n",
    "#     nn.Linear(128 * 2 * 2, 512), \n",
    "#     nn.ReLU(), \n",
    "#     nn.Dropout(0.2), \n",
    "#     nn.Linear(512, 200), \n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(0.2),\n",
    "#     nn.Linear(200, 100), \n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(0.2), \n",
    "#     nn.Linear(100, 10)        \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs):\n",
    "    train_losses = np.zeros(epochs)\n",
    "    test_losses = np.zeros(epochs)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        t0 = datetime.now()\n",
    "        train_loss = []\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_losses[epoch] = np.mean(train_loss)\n",
    "\n",
    "        test_loss = []\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss.append(loss.item())\n",
    "        test_losses[epoch] = np.mean(test_loss)\n",
    "\n",
    "        dt = datetime.now() - t0\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {np.mean(train_loss):.4f}, Test Loss: {np.mean(test_loss):.4f}, Duration: {dt}\")\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, test_losses = batch_gd(model, criterion, optimizer,\n",
    "                                  train_loader, test_loader, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train_loss\")\n",
    "plt.plot(test_losses, label=\"test_loss\")\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_correct = 0\n",
    "n_total = 0\n",
    "\n",
    "for inputs, targets in train_loader:\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    n_correct += (predictions == targets).sum().item()\n",
    "    n_total += targets.shape[0]\n",
    "\n",
    "test_acc = (n_correct / n_total) * 100\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc:.4f}%\")\n",
    "\n",
    "\n",
    "n_correct = 0\n",
    "n_total = 0\n",
    "\n",
    "for inputs, targets in test_loader:\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    n_correct += (predictions == targets).sum().item()\n",
    "    n_total += targets.shape[0]\n",
    "\n",
    "    train_acc = (n_correct / n_total) * 100\n",
    "print(f\"Train Accuracy: {train_acc:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confucsion_matrix(cm, classes, \n",
    "                           normalize=False,\n",
    "                           title=\"Confusion Matrix\", \n",
    "                           cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"normalized confusion matrix\")\n",
    "    else:\n",
    "        print(\"Confusion matrix, without normalization\")    \n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = \".2f\" if normalize else \"d\"\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),   \n",
    "                 horizontalalignment=\"center\",           \n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = \"\"\"T-shirt/top\n",
    "Trouser\n",
    "Pullover\n",
    "Dress\n",
    "Coat\n",
    "Sandal\n",
    "Shirt\n",
    "Sneaker\n",
    "Bag\n",
    "Ankle boot\"\"\".split(\"\\n\")\n",
    "\n",
    "x_test = test_dataset.data.numpy()\n",
    "y_test = test_dataset.targets.numpy()\n",
    "p_test = np.array([])\n",
    "\n",
    "for inputs, targets in test_loader:\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    p_test = np.concatenate((p_test, predictions.cpu().numpy()))\n",
    "\n",
    "cm = confusion_matrix(y_test, p_test)\n",
    "plot_confucsion_matrix(cm, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassifed_idx = np.where(p_test != y_test)[0]\n",
    "i = np.random.choice(misclassifed_idx)\n",
    "plt.imshow(x_test[i], cmap=\"gray\")\n",
    "plt.title(\"True Label: %s predicted: %s\" % (labels[y_test[i]], labels[int(p_test[i])]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
